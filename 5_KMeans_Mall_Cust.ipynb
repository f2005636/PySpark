{"cells":[{"cell_type":"code","source":["df = sqlContext.sql(\"select * from mall_customers\")\ndf = df.drop('CustomerID')\ndf.printSchema()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.ml.feature import StandardScaler,VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer\nfrom pyspark.ml.clustering import KMeans"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["indexer = StringIndexer(inputCol=\"Genre\", outputCol=\"Sex\")\nindexed = indexer.fit(df).transform(df)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols=['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Sex'],outputCol=\"features\")\noutput = assembler.transform(indexed)\nfinal_data = output.select(\"features\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\nscalerModel = scaler.fit(final_data)\ncluster_final_data = scalerModel.transform(final_data)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["for k in range(2,11):\n    kmeans = KMeans(featuresCol='scaledFeatures',k=k)\n    model = kmeans.fit(cluster_final_data)\n    wssse = model.computeCost(cluster_final_data)\n    print(\"With K={}\".format(k))\n    print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n    print('--'*30)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["kmeans = KMeans(featuresCol='scaledFeatures',k=6)\nmodel_kmeans = kmeans.fit(cluster_final_data)\nmodel_kmeans.transform(cluster_final_data).groupBy('prediction').count().show()\nprint('\\n')\ncenters = model_kmeans.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{},"outputs":[],"execution_count":7}],"metadata":{"name":"k_means","notebookId":4312032934767632},"nbformat":4,"nbformat_minor":0}
